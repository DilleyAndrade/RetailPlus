# ğŸ“Š Data Pipeline - Projeto de ETL e Modelagem

Este projeto implementa um pipeline de dados simples para simular o processo de **ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga (ETL)**, seguido de **modelagem relacional e dimensional**. Ele utiliza arquivos CSV como fonte de dados, scripts Python para carregamento e SQL para preparaÃ§Ã£o e anÃ¡lise dos dados.

---

## ğŸ—‚ Estrutura do Projeto

```
.
â”œâ”€â”€ data/                # Dados brutos utilizados como fonte
â”‚   â”œâ”€â”€ customers.csv
â”‚   â”œâ”€â”€ orders.csv
â”‚   â””â”€â”€ products.csv
â”‚
â”œâ”€â”€ diagrams/            # EspaÃ§o reservado para diagramas do modelo de dados (opcional)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ load_data.py     # Script para carregar os arquivos CSV no banco de dados
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ create_tables.sql    # CriaÃ§Ã£o das tabelas no banco
â”‚   â”œâ”€â”€ clean_data.sql       # Limpeza e padronizaÃ§Ã£o dos dados carregados
â”‚   â”œâ”€â”€ build_fact_dim.sql   # CriaÃ§Ã£o de tabelas fato e dimensÃ£o para anÃ¡lise
â”‚   â””â”€â”€ queries.sql          # Consultas analÃ­ticas e de validaÃ§Ã£o
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Fluxo de ExecuÃ§Ã£o

1. **Crie as tabelas no banco de dados**
   - Execute o script SQL `create_tables.sql` para criar a estrutura do banco.
   - Arquivo: `sql/create_tables.sql`

2. **Carregar os Dados**
   - Execute o script Python que lÃª os arquivos `.csv` da pasta `data/` e insere os dados em tabelas temporÃ¡rias no banco.
   - Arquivo: `scripts/load_data.py`

3. **Criar Tabelas**
   - Executar o SQL que cria a estrutura inicial do banco relacional.
   - Arquivo: `sql/create_tables.sql`

4. **Limpar os Dados**
   - Aplicar transformaÃ§Ãµes para corrigir inconsistÃªncias e padronizar valores.
   - Arquivo: `sql/clean_data.sql`

5. **Construir Modelo Dimensional**
   - Criar tabelas fato e dimensÃµes a partir dos dados limpos para anÃ¡lises futuras.
   - Arquivo: `sql/build_fact_dim.sql`

6. **Executar Consultas**
   - Validar o modelo e gerar insights por meio de consultas SQL.
   - Arquivo: `sql/queries.sql`

---

## ğŸ“¦ PrÃ©-requisitos

- Python 3.x
- Biblioteca `pandas` (para manipulaÃ§Ã£o dos CSVs)
- Banco de dados PostgreSQL
- Cliente SQL ou IDE (DBeaver, VSCode com extensÃ£o SQL, etc.)

---

## ğŸš€ Como Executar

1. Clone este repositÃ³rio:
   ```bash
   git clone <url-do-repositorio>
   cd <nome-da-pasta>
   ```

2. Instale as dependÃªncias do Python:
   ```bash
   pip install pandas sqlalchemy
   ```

3. Execute o carregamento dos dados:
   ```bash
   python scripts/load_data.py
   ```

4. Rode os scripts SQL na ordem:
   - `create_tables.sql`
   - `clean_data.sql`
   - `build_fact_dim.sql`
   - `queries.sql`

---

## ğŸ“Œ ObservaÃ§Ãµes

- Os arquivos CSV simulam entidades de um cenÃ¡rio de vendas: **clientes, pedidos e produtos**.
- A pasta `diagrams/` pode ser usada para armazenar diagramas ER e de modelo dimensional criados durante o projeto.
- Este projeto serve como base para estudos de engenharia de dados e modelagem de banco de dados.

